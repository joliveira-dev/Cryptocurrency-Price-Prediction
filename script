import ccxt
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from keras.layers import Input


# ======================================================= #
# Defining configuration variables at the beginning
epochs_ = 50                          # Number of epochs
batch_size_ = 64                       # Batch size
units_lstm_ = 100                      # Number of LSTM units
dropout_rate_ = 0.3                    # Dropout rate
time_step_ = 30                        # Time step for the model
optimizer_ = 'adam'                    # Optimizer
loss_function_ = 'mean_squared_error'  # Loss function


# ======================================================= #
# Initializes the connection with Coinbase Pro
exchange_coinbase = ccxt.coinbase()
symbol = 'BTC/USD'  # Using the USD pair
timeframe = '1d'  # Daily

# List to store the complete data
all_data = []

# Initializes "since" with the start date
since = exchange_coinbase.parse8601('2021-01-01T00:00:00Z')  # Adjust the date as needed

while True:
    # Fetch OHLCV data from the current "since"
    ohlcv = exchange_coinbase.fetch_ohlcv(symbol, timeframe, since=since)
    if not ohlcv:
        break  # Ends the loop if no more data is available

    # Adds the data to the main list
    all_data.extend(ohlcv)

    # Updates "since" to the next date after the last timestamp obtained
    since = ohlcv[-1][0] + 1  # Adds 1 ms to avoid duplicate data

# Converts the complete data to a DataFrame
df = pd.DataFrame(all_data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
df.set_index('timestamp', inplace=True)

# Initializes the connection with Binance to get the exchange rate and converts the EUR/USDT rate to USD/EUR
usd_eur_rate = 1 / ccxt.binance().fetch_ticker('EUR/USDT')['close']

# Converting prices from USD to EUR
df[['open', 'high', 'low', 'close']] = df[['open', 'high', 'low', 'close']] * usd_eur_rate

# Display the resulting DataFrame in EUR
print(df)


# ======================================================= #
# Normalizes the closing price                            
scaler = MinMaxScaler(feature_range=(0, 1))
data_scaled = scaler.fit_transform(df['close'].values.reshape(-1, 1))

# Function to create data sequences for the LSTM
def create_dataset(data, time_step=time_step_):
    X, y = [], []
    for i in range(len(data) - time_step):
        X.append(data[i:(i + time_step), 0])  # Sequence of 30 days
        y.append(data[i + time_step, 0])  # Future price
    return np.array(X), np.array(y)

# Creating the sequences
X, y = create_dataset(data_scaled)

# Reshaping to the format expected by LSTM
X = X.reshape(X.shape[0], X.shape[1], 1)

# Displaying the shapes of X and y
X.shape, y.shape


# ======================================================= #
# Splitting the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

# Checking the dimensions of the training and testing sets
X_train.shape, X_test.shape


# ======================================================= #
# Defining the input layer of the model
input_layer = Input(shape=(X_train.shape[1], 1))

# Building the LSTM model
model = Sequential()
model.add(input_layer)  # Using the Input layer
model.add(LSTM(units=units_lstm_, return_sequences=True))
model.add(Dropout(dropout_rate_))  # Regularization

# Second LSTM layer
model.add(LSTM(units=units_lstm_, return_sequences=False))
model.add(Dropout(dropout_rate_))

# Dense layer for predicting the future value
model.add(Dense(units=1))  # Output with 1 value (future price)

# Compiling the model
model.compile(optimizer=optimizer_, loss=loss_function_)

# Model summary
model.summary()


# ======================================================= #
# Training the model
history = model.fit(X_train, y_train, epochs=epochs_, batch_size=batch_size_, validation_data=(X_test, y_test))

# Visualizing the loss during training
train_loss = history.history['loss']
val_loss = history.history['val_loss']

plt.plot(train_loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.legend()
plt.title('Model Loss during Training')
plt.xlabel('Epochs')
plt.ylabel('Loss (MSE)')
plt.show()


# ======================================================= #
# Making predictions with the test data
predicted_price = model.predict(X_test)

# Reversing the normalization of the data
predicted_price = scaler.inverse_transform(predicted_price)
y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))

# Plotting the predictions versus the actual values
plt.figure(figsize=(10,6))
plt.plot(y_test_actual, label='Actual Price')
plt.plot(predicted_price, label='Predicted Price')
plt.legend()
plt.title('Closing Price Prediction - BTC/USDT')
plt.xlabel('Time Index')
plt.ylabel('Price')
plt.show()


# ======================================================= #
# Final evaluation with Mean Squared Error (MSE)
mse = mean_squared_error(y_test_actual, predicted_price)
print(f"Mean Squared Error (MSE): {mse}")


# ======================================================= #
# Let's create the sequence for the last day (or any more recent date)
last_data = data_scaled[-30:]  # Get the last 30 days of normalized data

# Making the prediction for the next day
next_day_prediction = model.predict(last_data.reshape(1, 30, 1))

# Reverting the normalization
next_day_prediction = scaler.inverse_transform(next_day_prediction)
print(f"Predicted Price for the next day: {next_day_prediction[0][0]}")


